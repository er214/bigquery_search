{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "This notebook provides examples of code to use word vectors to create a natural language type search facility in BigQuery. It accompanies a blog post which explains how it all works. \n",
        "\n",
        "You can find the blog post here:\n",
        "https://www.efficientdatagroup.com/blog/natural-language-search-in-google-bigquery\n"
      ],
      "metadata": {
        "id": "3azViXq824Vz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "i3VeHSckwl9p"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set the name of the project in the following cell. This will be inserted into SQL queries througohut the notebook. "
      ],
      "metadata": {
        "id": "IxrMGlXDz1Kz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "project_id = 'news-209921'\n",
        "project_id = 'enter-your-project-name-here'"
      ],
      "metadata": {
        "id": "69Cgi1hVxRSD"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Connect to the project and list datasets. This should contain a dataset called 'word_vectors_us'.\n",
        "\n",
        "from google.cloud import bigquery\n",
        "client = bigquery.Client(project=project_id)\n",
        "\n",
        "for dataset in client.list_datasets():\n",
        "  print(dataset.dataset_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "misRfFkEwl9r",
        "outputId": "25ca088e-094f-4b54-864a-18859a3d6695"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "word_vectors_us\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u6JTwU8R0Psz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run a word similarity query"
      ],
      "metadata": {
        "id": "p1Ex3oKq0a92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_sim = f\"\"\"WITH \n",
        "  glove AS (SELECT * FROM `{project_id}.word_vectors_us.glove_vectors`),\n",
        "\n",
        "  search_vector AS (SELECT * FROM  glove \n",
        "            WHERE word = @search_word),\n",
        "\n",
        "  cosine_sim AS (  \n",
        "      SELECT  \n",
        "          all_vectors.word,\n",
        "          (SELECT #  u⋅v / (∥u∥ * ∥v∥)\n",
        "              SUM(av_component * sv_component) / \n",
        "             ( SQRT(SUM(av_component * av_component)) * \n",
        "                  SQRT(SUM(sv_component * sv_component)) ) \n",
        "            FROM \n",
        "              UNNEST(all_vectors.vector)   av_component WITH OFFSET av_component_index\n",
        "            JOIN\n",
        "              UNNEST(search_vector.vector) sv_component WITH OFFSET sv_component_index\n",
        "            ON av_component_index = sv_component_index\n",
        "          ) AS cosine_similarity\n",
        "    FROM glove AS all_vectors \n",
        "    CROSS JOIN search_vector\n",
        "  )\n",
        "\n",
        "SELECT * FROM cosine_sim\n",
        "ORDER BY cosine_similarity DESC\n",
        "LIMIT 10\"\"\""
      ],
      "metadata": {
        "id": "1eoHoxgT0dlh"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose the word you want to do the similarity search for below\n",
        "search_term = \"aubergine\"\n",
        "job_config = bigquery.QueryJobConfig(\n",
        "    query_parameters=[\n",
        "        bigquery.ScalarQueryParameter(\"search_word\", \"STRING\", search_term),\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "ZRvIydI81HkY"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job = client.query(word_sim, job_config=job_config)\n",
        "res = job.result().to_dataframe()\n",
        "res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "vPojv7RDysoK",
        "outputId": "a3d7e708-1dfd-4b54-ce89-f317a55f51f9"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         word  cosine_similarity\n",
              "0   aubergine           1.000000\n",
              "1    eggplant           0.814989\n",
              "2   courgette           0.740594\n",
              "3  aubergines           0.709632\n",
              "4    beetroot           0.680378\n",
              "5    caponata           0.653725\n",
              "6   eggplants           0.646994\n",
              "7  courgettes           0.644074\n",
              "8    tapenade           0.621136\n",
              "9    zucchini           0.618107"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4e541ba6-195b-4ce6-8873-2da586934644\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word</th>\n",
              "      <th>cosine_similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>aubergine</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>eggplant</td>\n",
              "      <td>0.814989</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>courgette</td>\n",
              "      <td>0.740594</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>aubergines</td>\n",
              "      <td>0.709632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>beetroot</td>\n",
              "      <td>0.680378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>caponata</td>\n",
              "      <td>0.653725</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>eggplants</td>\n",
              "      <td>0.646994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>courgettes</td>\n",
              "      <td>0.644074</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>tapenade</td>\n",
              "      <td>0.621136</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>zucchini</td>\n",
              "      <td>0.618107</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4e541ba6-195b-4ce6-8873-2da586934644')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4e541ba6-195b-4ce6-8873-2da586934644 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4e541ba6-195b-4ce6-8873-2da586934644');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create tokeniser"
      ],
      "metadata": {
        "id": "D1drSHaX2Yn7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokeniser = f\"\"\"CREATE OR REPLACE FUNCTION `{project_id}.word_vectors_us.tokenise_no_stop`(text STRING) AS (\n",
        "(\n",
        "    SELECT ARRAY_AGG(word) FROM UNNEST(REGEXP_EXTRACT_ALL(\n",
        "                                REGEXP_REPLACE(text, r''|\\'s(\\W)', r'\\1'),\n",
        "                                r'((?:\\d+(?:,\\d+)*(?:\\.\\d+)?)+|(?:[\\w])+)')) AS word\n",
        "    WHERE LOWER(word) not in UNNEST(['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', 'arent', 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', 'couldnt', 'd', 'did', 'didn', 'didnt', 'do', 'does', 'doesn', 'doesnt', 'doing', 'don', 'dont', 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', 'hadnt', 'has', 'hasn', 'hasnt', 'have', 'haven', 'havent', 'having', 'he', 'her', 'here', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in', 'into', 'is', 'isn', 'isnt', 'it', 'its', 'itself', 'just', 'll', 'm', 'ma', 'me', 'mightn', 'mightnt', 'more', 'most', 'mustn', 'mustnt', 'my', 'myself', 'needn', 'neednt', 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', 'shant', 'she', 'shes', 'should', 'shouldn', 'shouldnt', 'shouldve', 'so', 'some', 'such', 't', 'than', 'that', 'thatll', 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', 'wasnt', 'we', 'were', 'weren', 'werent', 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', 'wont', 'wouldn', 'wouldnt', 'y', 'you', 'youd', 'youll', 'your', 'youre', 'yours', 'yourself', 'yourselves', 'youve'])\n",
        "    )\n",
        ");\"\"\""
      ],
      "metadata": {
        "id": "CrIgYZntzCIP"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job = client.query(tokeniser)\n",
        "res = job.result()"
      ],
      "metadata": {
        "id": "4omyt-bEzCyl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculate word frequencies and save"
      ],
      "metadata": {
        "id": "PUI-jHHH3y5R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_frequencies = f\"\"\"CREATE OR REPLACE TABLE \n",
        "    `{project_id}.word_vectors_us.word_frequencies` AS\n",
        "\n",
        "WITH tokens AS (\n",
        "  SELECT `{project_id}.word_vectors_us.tokenise_text`(body) AS tk \n",
        "  FROM `bigquery-public-data.breathe.nature`\n",
        ")\n",
        "SELECT w AS word, COUNT(*) AS frequency\n",
        "FROM tokens, UNNEST(tk) AS w\n",
        "GROUP BY 1\"\"\""
      ],
      "metadata": {
        "id": "qvvKxYAH3ZZi"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job = client.query(word_frequencies)\n",
        "res = job.result()"
      ],
      "metadata": {
        "id": "7tC3ltuJ3ZcM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the document vectors"
      ],
      "metadata": {
        "id": "-bCNrylU4ApR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following query creates document vectors for all the Nature articles in the breathe dataset. It is based on the body text.\n",
        "Note that some of the article entries are missing body text, and so nothing is produced."
      ],
      "metadata": {
        "id": "TlVtoUXc4jkc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "n9nVY6tQ40st"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "create_doc_vectors = f\"\"\"CREATE OR REPLACE TABLE `{project_id}.word_vectors_us.nature_vectors`\n",
        "AS\n",
        "\n",
        "WITH all_articles AS (SELECT  id,\n",
        "                              date,\n",
        "                              title, \n",
        "                              `{project_id}.word_vectors_us.tokenise_no_stop`(body) article \n",
        "\n",
        "FROM `bigquery-public-data.breathe.nature`),\n",
        "\n",
        "# Unnest so we have one word per row\n",
        "my_word_lists AS (\n",
        "            SELECT  id, \n",
        "                    word \n",
        "            FROM all_articles, UNNEST(article) AS word \n",
        "   ),\n",
        "\n",
        "# Fetch the vectors for each word and weight by word frequency\n",
        "lookup_vectors AS (\n",
        "  SELECT  \n",
        "        id,\n",
        "        word, \n",
        "        wv_component / POW(frequency, 0.4) AS tf_normalised_wv_component, \n",
        "        wv_component_index  \n",
        "  FROM my_word_lists \n",
        "  JOIN `{project_id}.word_vectors_us.glove_vectors` \n",
        "    USING (word)\n",
        "  JOIN `{project_id}.word_vectors_us.word_frequencies`\n",
        "    USING (word)\n",
        "  , UNNEST(vector) wv_component WITH OFFSET wv_component_index),\n",
        "\n",
        "# Aggregate to create a document vector\n",
        "aggregate_vectors_over_article AS (\n",
        "  SELECT   id,\n",
        "           wv_component_index, \n",
        "           SUM(tf_normalised_wv_component) aggregated_wv_component \n",
        "  FROM lookup_vectors \n",
        "  GROUP BY id, wv_component_index),\n",
        "\n",
        "# Normalise vectors to unit length, so need to work out the length (magnitude)\n",
        "vector_lengths AS (\n",
        "  SELECT id, \n",
        "         SQRT(SUM(aggregated_wv_component * aggregated_wv_component)) AS magnitude \n",
        "  FROM aggregate_vectors_over_article\n",
        "  GROUP BY id),\n",
        "\n",
        "# Divide by the magnitude to normalise and put it back in to an array\n",
        "normalised_aggregate_vectors AS (\n",
        "    SELECT id,  \n",
        "           ARRAY_AGG(aggregated_wv_component / magnitude ORDER BY wv_component_index) AS article_vector\n",
        "    FROM aggregate_vectors_over_article \n",
        "    JOIN vector_lengths\n",
        "      USING (id)\n",
        "    GROUP BY id)\n",
        "\n",
        "SELECT  id, \n",
        "        date, \n",
        "        title, \n",
        "        article_vector \n",
        "FROM normalised_aggregate_vectors\n",
        "JOIN all_articles\n",
        "USING (id)\"\"\""
      ],
      "metadata": {
        "id": "4PVJLdp53Zhq"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job = client.query(create_doc_vectors)\n",
        "res = job.result()"
      ],
      "metadata": {
        "id": "6__kAXpR4ubY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create function to perform natural language search"
      ],
      "metadata": {
        "id": "oUjguYYb41rV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_search = f\"\"\"CREATE OR REPLACE PROCEDURE `{project_id}.word_vectors_us.similarity_search`(search_phrase STRING)\n",
        "BEGIN\n",
        "\n",
        "WITH \n",
        "  all_tokens AS (SELECT  `{project_id}.word_vectors_us.tokenise_no_stop`(search_phrase) tokens),\n",
        "\n",
        "  # Unnest so we have one word per row\n",
        "  tokens_no_stops AS (\n",
        "            SELECT  word \n",
        "            FROM all_tokens, UNNEST(tokens) AS word \n",
        "   ),\n",
        "\n",
        "  # Fetch vectors for each word, and weight by the word frequency in the corpus \n",
        "  lookup_vectors AS (SELECT  \n",
        "                            word, \n",
        "                            vector_component / POW(frequency, 0.4) AS weighted_vector_component, \n",
        "                            vector_component_index  \n",
        "  FROM tokens_no_stops \n",
        "  JOIN `{project_id}.word_vectors_us.glove_vectors` \n",
        "  USING (word)\n",
        "  JOIN `{project_id}.word_vectors_us.word_frequencies`\n",
        "  USING (word)\n",
        "  , \n",
        "  UNNEST(vector) vector_component WITH OFFSET vector_component_index),\n",
        "\n",
        "  # Aggregate the weighted components to generate a single vectors. Just take the SUM\n",
        "  aggregate_vector AS (SELECT vector_component_index, SUM(weighted_vector_component) AS agg_vector_component \n",
        "                    FROM lookup_vectors \n",
        "                    GROUP BY vector_component_index),\n",
        "\n",
        "  # We want to normalise the vectors to unit length, so need to work out the length (magnitude) of the \n",
        "  vector_length AS (SELECT SQRT(SUM(agg_vector_component * agg_vector_component)) AS magnitude \n",
        "  FROM aggregate_vector),\n",
        "\n",
        "  # Divide by the magnitude to normalise and put it back in to an array\n",
        "  norm_vector AS (\n",
        "    SELECT ARRAY_AGG(agg_vector_component / (SELECT magnitude FROM vector_length) ORDER BY vector_component_index) AS vector\n",
        "    FROM aggregate_vector)\n",
        "\n",
        "SELECT  id,\n",
        "        date,\n",
        "        title,\n",
        "        (SELECT SUM(doc_vector_component * search_vector_component) \n",
        "         FROM \n",
        "            UNNEST(dv.article_vector) doc_vector_component WITH OFFSET dv_component_index\n",
        "         JOIN\n",
        "            UNNEST(s.vector) search_vector_component WITH OFFSET sv_component_index\n",
        "         ON dv_component_index = sv_component_index) AS cosine_similarity\n",
        "FROM `{project_id}.word_vectors_us.nature_vectors` dv\n",
        "CROSS JOIN norm_vector s\n",
        "ORDER BY cosine_similarity DESC\n",
        "LIMIT 10;\n",
        "END;\"\"\""
      ],
      "metadata": {
        "id": "Jh8cuqAh49He"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job = client.query(my_search)\n",
        "res = job.result()"
      ],
      "metadata": {
        "id": "BQhcHSuD5G2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Example search"
      ],
      "metadata": {
        "id": "yDxQfnXC5TS6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job = client.query(f\"\"\"CALL `{project_id}.word_vectors_us.similarity_search`(\n",
        "  \"Epigenetics and cerebral organoids: promising directions in autism spectrum disorders\"\n",
        ");\"\"\" )"
      ],
      "metadata": {
        "id": "CClg6cH25MS9"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res = job.result().to_dataframe()"
      ],
      "metadata": {
        "id": "hi9sbBRj5MPp"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "uI4V6H3i5MHJ",
        "outputId": "da062803-df86-4f4c-89b2-4a3af5c2311e"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                     id        date  \\\n",
              "0  5de2010b-bee3-4669-aa24-8287a8ab6fd9  2018-01-10   \n",
              "1  361dd572-e745-4691-8822-232b052cb842  2018-05-30   \n",
              "2  d779f221-da50-448f-9094-7450b0c67df8  2018-02-01   \n",
              "3  230182c6-4362-4291-bb47-31a3e7b35d9c  2020-04-22   \n",
              "4  be8d2d29-b47e-4273-9867-7307853e02bc  2017-09-13   \n",
              "5  ad05a0b9-d8c0-4042-a0bf-0bf79ce1b366  2018-06-11   \n",
              "6  aa5ff4b3-86c5-4e72-b4c1-f121ea2a0ab9  2019-01-18   \n",
              "7  6c1d8d18-7c92-4f5f-96a5-582bf67f5e0d  2019-01-18   \n",
              "8  2f256d20-f728-4a06-81b7-716ed4534139  2018-02-26   \n",
              "9  8c839857-09dd-43b6-be3c-106e02f1e388  2020-02-28   \n",
              "\n",
              "                                               title  cosine_similarity  \n",
              "0  Epigenetics and cerebral organoids: promising ...           0.601886  \n",
              "1  Investigating pediatric disorders with induced...           0.597278  \n",
              "2  Modeling cancer using patient-derived induced ...           0.576579  \n",
              "3  Epigenetic mechanism of SETDB1 in brain: impli...           0.571364  \n",
              "4  Toxoplasma Modulates Signature Pathways of Hum...           0.570963  \n",
              "5  Review and gap analysis: molecular pathways le...           0.564909  \n",
              "6  Insights into genetics, human biology and dise...           0.563441  \n",
              "7  Insights into genetics, human biology and dise...           0.563441  \n",
              "8  Synaptic and transcriptionally downregulated g...           0.559447  \n",
              "9  Beyond the looking glass: recent advances in u...           0.558771  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d5b8d4a0-e611-4501-8626-ae26b0461881\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>date</th>\n",
              "      <th>title</th>\n",
              "      <th>cosine_similarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5de2010b-bee3-4669-aa24-8287a8ab6fd9</td>\n",
              "      <td>2018-01-10</td>\n",
              "      <td>Epigenetics and cerebral organoids: promising ...</td>\n",
              "      <td>0.601886</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>361dd572-e745-4691-8822-232b052cb842</td>\n",
              "      <td>2018-05-30</td>\n",
              "      <td>Investigating pediatric disorders with induced...</td>\n",
              "      <td>0.597278</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>d779f221-da50-448f-9094-7450b0c67df8</td>\n",
              "      <td>2018-02-01</td>\n",
              "      <td>Modeling cancer using patient-derived induced ...</td>\n",
              "      <td>0.576579</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>230182c6-4362-4291-bb47-31a3e7b35d9c</td>\n",
              "      <td>2020-04-22</td>\n",
              "      <td>Epigenetic mechanism of SETDB1 in brain: impli...</td>\n",
              "      <td>0.571364</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>be8d2d29-b47e-4273-9867-7307853e02bc</td>\n",
              "      <td>2017-09-13</td>\n",
              "      <td>Toxoplasma Modulates Signature Pathways of Hum...</td>\n",
              "      <td>0.570963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ad05a0b9-d8c0-4042-a0bf-0bf79ce1b366</td>\n",
              "      <td>2018-06-11</td>\n",
              "      <td>Review and gap analysis: molecular pathways le...</td>\n",
              "      <td>0.564909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>aa5ff4b3-86c5-4e72-b4c1-f121ea2a0ab9</td>\n",
              "      <td>2019-01-18</td>\n",
              "      <td>Insights into genetics, human biology and dise...</td>\n",
              "      <td>0.563441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>6c1d8d18-7c92-4f5f-96a5-582bf67f5e0d</td>\n",
              "      <td>2019-01-18</td>\n",
              "      <td>Insights into genetics, human biology and dise...</td>\n",
              "      <td>0.563441</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>2f256d20-f728-4a06-81b7-716ed4534139</td>\n",
              "      <td>2018-02-26</td>\n",
              "      <td>Synaptic and transcriptionally downregulated g...</td>\n",
              "      <td>0.559447</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>8c839857-09dd-43b6-be3c-106e02f1e388</td>\n",
              "      <td>2020-02-28</td>\n",
              "      <td>Beyond the looking glass: recent advances in u...</td>\n",
              "      <td>0.558771</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d5b8d4a0-e611-4501-8626-ae26b0461881')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d5b8d4a0-e611-4501-8626-ae26b0461881 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d5b8d4a0-e611-4501-8626-ae26b0461881');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GP_uOJSw5pcF"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}